#!@PYTHON_EXECUTABLE@

#------------------------------------------------------------------------
__doc__="""\
gpu_sdfits - conversion of GPU spectrograph spectra and metadata into
          SDFITS style FITS files. The aim is to be run directly from
          the command line with little or no information beyond the
          pointer to the directory tree with the GPU spectrometer
          data. 

 Uses: gpu_read.py

 Assume:
  Each subdirectory has a set of spectra and noise files and one metadata
  file to go with it. The aim will be to encapsulate all the spectra and
  noise files into one fits file, merging in the metadata.

 - within each subdirectory:
  = check for existing fits file for the subdirectory
  = list files
  = read in the metadata file first
   * construct needed metadata based FITS header information
   * construct needed lookup tables
  = loop over input noise files - sorted in time order
  = loop over input spectra files - sorted in time order
  = construct output SDFITS file(s)

 Debugging tip: 
 - Dump output binary tables using futils_tablist to check that the 
   columns are in fact what you think they are
 - or check structure with fitsinfo (from the HEASARC fits package)

 Table columns will have to be built up row by row, so append to each
 column as each spectrum and its associated metadata are read and
 parsed.

 Structure:
  - primary HDU
  - spectrum binary table (named MATRIX)

 Operational order:
  1) construct list of directory(ies) and the files there-in.
  2) Test for existing FITS file that would be auto-constructed from
    the directory. If found, go to next directory. If override, then
    reconstruct anyway.
  3) read in meta-data.json file for the directory (assuming there is
    only 1).
  4) loop over noise power files:
    (a) construct metadata at time of noise reading
    (b) add noise power info to the metadata available
    (c) sort based on datetime to ensure they are in time order
  5) loop over spectrum files:
    (a) construct metadata at time of spectrum
    (b) add metadata to the column lists
    (c) add spectrum to the data matrix list
    (d) sort based on datetime to ensure they are in time order
  6) Construct FITS - primary HDU, spectrum binary table HDU, noise 
    binary table HDU.
"""
__usage__="""\
 Usage: ./gpu_sdfits.py Directory [optional: NumberRawSpecToAverage]

 If directory contains wildcards, then you should quote it to avoid
 expansion by the shell. So, for example:
    sh> ./gpu_sdfits.py ../Data/scan[12]
 will do ../Data/scan1
    sh> ./gpu_sdfits.py '../Data/scan[12]'
 will do ../Data/scan1 and ../Data/scan2

 This takes an optional second argument NumberRawSpecToAverage, which
 is the number of raw spectra to average together into a single mean
 spectrum when converting to FITS. E.g. If there are 2400 raw spectra,
 and NumberRawSpecToAverage is 12, then 200 average spectra will get
 written to the FITS file. No rebinning or frequency shifting is done.
 The spectra are assumed to be temporally close enough to skip that.
 This also computes all the associated data/metadata for the averaged
 spectrum.

 [NB, for the moment, all the spectra are assumed to be of the same
 object and observing setup - ie, for now, all are assumed of the same
 polarization etc. Refinements to split multiple observation
 characteristics apart will be added later.]

 This will check each directory to see if there is already a FITS
 file.  If ANY FITS files are found in the directory, this will skip
 the directory to avoid possibly overwriting data.

 The FITS file will be named based on the basename of the
 directory. So, for the directory Data/scan6/, the FITS file will be
 Data/scan6/scan6.fits.

 If the program is run as:
   gpu_sdfits.py '.'
 or
   gpu_sdfits.py './'
 it will check the absolute pathname of the current directory and construct
 the FITS file name based on the basename returned.
"""
__author__="S. Levine"
__date__="2019 Jul 26"

#------------------------------------------------------------------------
# import the FITS io routines for the I/O
from astropy.io import fits

# import astropy coordinates routines
from astropy.coordinates import EarthLocation, SkyCoord, AltAz, ICRS, Galactic, Galactocentric
from astropy.time        import Time
import astropy.units     as u

# JSON reading routines
import json

# import numpy for its array handling
import numpy as np

# time/date routines
from time import gmtime, strftime
import datetime as dt

# system path operations
import os

# GPU file reading and parsing classes/routines
import gpu_read as r

# random was used for some testing. can be removed.
import random

#------------------------------------------------------------------------
# Various Solar Motion constants wrt the LSR.
# - the one in use is uvw_klb as the Standard Solar Motion
# - See longer notes in the function altaz2radec()

# Kerr & Lynden-Bell, 1986, MNRAS, 221, 1023
# Nominal "Standard Solar Motion"
uvw_klb = [10.0, 15.4, 7.8] * u.kilometer / u.second

# Dehnen & Binney 1998, based on Hipparcos
uvw_db98 = [10.0, 5.2, 7.2] * u.kilometer / u.second

# Schonrich et al, 2010, MNRAS, 403, 1829
uvw_sbd10 = [11.1, 12.24, 7.25] * u.kilometer / u.second
#------------------------------------------------------------------------

# data structure for global metadata
site_meta  = {'origin' : None}
wthr_meta  = {'temp'   : None}
coord_meta = {'alt'    : None}
wcs_meta   = {'maxis'  : None}

# Spectrum dictionary - it is structured as a dictionary of lists for
#  compatibility with the FITS binary table column construction.
obs_spec = {'spec_idx':[],
            'datetime': [], 'date-obs': [], 'ut': [], 'object': [],
            'obstime': [], 'experiment': [], 'scan': [], 'scan_name': [],
            'navg': [],
            'spec_len': [], 'spec_data_type': [], 'spec': [],
            'az': [], 'el':[],
            'crval_freq': [], 'crpix_freq': [], 'cdelt_freq': [],
            'src_id': [], 'src_ra': [], 'src_dec':[],
            'src_ra_deg': [], 'src_dec_deg':[],
            'samp_len':[], 'samp_rate':[],
            'tsys':[], 'vdef':[]}

# combined n-to-1 spectral records
cmb_spec = {'spec_idx':[],
            'datetime': [], 'date-obs': [], 'ut': [], 'object': [],
            'obstime': [], 'experiment': [], 'scan': [], 'scan_name': [],
            'navg': [],
            'spec_len': [], 'spec_data_type': [], 'spec': [],
            'az': [], 'el':[],
            'crval_freq': [], 'crpix_freq': [], 'cdelt_freq': [],
            'src_id': [], 'src_ra': [], 'src_dec':[],
            'src_ra_deg': [], 'src_dec_deg':[],
            'samp_len':[], 'samp_rate':[],
            'tsys':[], 'vdef':[]}

# Noise dictionary
obs_nois   = {'datetime': [], 'date-obs': [], 'ut': [], 'object': [],
              'obstime': [], 'experiment': [], 'scan': [], 'scan_name': [],
              'accum_len': [], 'switch_freq': [], 'blanking_per': [],
              'noise': [], 'mean_power_on': [], 'mean_power_off': [], 
              'az': [], 'el':[]}

#------------------------------------------------------------------------
# Functions

def sort_dict_of_lists (input_dict, srtkey):
    """\
    Given a dictionary with a set of lists, sort all the
    lists based on one of the lists. Return a dict with
    the sorted lists.
    """
    
    # To be used to ensure that each array in input_dict is in
    # increasing primary key sort order. Set up separate list of
    # primary sort key then zip together all the other obs_spec lists
    # after the sort index. Sort and then copy into the return
    # dictionary.

    j = sorted (input_dict.keys())
    tmp_sort_arr = input_dict[srtkey]
    tmppack = zip(tmp_sort_arr, *(input_dict[k] for k in j))
    srtpack = map(list, zip(*sorted(tmppack)))
    sidx = 1
    ret_dict = {}
    for k in j:
        ret_dict[k] = srtpack[sidx]
        sidx += 1

    return ret_dict

def find_index (input_list, match_value, rtype='nearest'):
    """\
    Find the index value of the record in a pre-sorted list
    that is closest to match_value based on the rtype method, where
        rtype - return type method 
              = interp == interpolation
                prevval == previous value before requested index
                nexttval == next value after requested index
                nearest == nearest value in index
    """
    il_len = len(input_list)
    retval = -1

    if (il_len < 1):
        # no elements in list
        retval = -1

    elif (il_len == 1):
        # single element list
        retval = 0

    else:
        if (match_value <= input_list[0]):
            # before the list
            retval = 0

        elif ( match_value > input_list[-1]):
            # after end of the list
            retval = -1

        else:
            for j in range(il_len - 1):
                if ((match_value >  input_list[j]) and
                    (match_value <= input_list[j+1])):
                    q = j
                    r = j+1
                    break
            a = (match_value - input_list[j])
            b = (input_list[j+1] - match_value)

            if (rtype == 'prevval'):
                retval = q
                            
            elif (rtype == 'nextval'):
                retval = r
                            
            elif (rtype == 'nearest'):
                if (a < b):
                    retval = q
                else:
                    retval = r

    return retval

def simple_combine_spec (num_to_avg):
    """\
    Bin together raw spectral records. Take num_to_avg raw records
    and combine into a single higher s/n spectral record.
    Some columns get averaged, others summed, some just take extrema.
    This assumes that obs_spec is pre-sorted in time.
    If the number of raw spectra is not divisible by num_to_avg, the 
    remainder raw spectra are simply dropped. This way, all the combined
    spectra have the same characteristics.
    """

    global obs_spec
    global cmb_spec

    # number of raw spectral records
    os_len = len(obs_spec['spec_idx'])

    # Figure out number of records less than or equal to os_len that
    # num_to_avg divides (to avoid walking of the end of the array by
    # stepping beyond the last few spectral records).
    cmb_len = os_len - (os_len % num_to_avg)

    print ('os_len, cmb_len = {}, {}'.format(os_len, cmb_len))

    k = 0
    for i in range (0, cmb_len, num_to_avg):
        # Those items which are set once per combined spectral record
        # Typically based on the beginning of the duration (like the
        # start of the integration time in UT).

        # cmb_spec['spec_idx'].append(k)
        cmb_spec['spec_idx'].append(obs_spec['spec_idx'][i])
        cmb_spec['vdef'].append(obs_spec['vdef'][i])

        cmb_spec['datetime'].append(obs_spec['datetime'][i])
        cmb_spec['date-obs'].append(obs_spec['date-obs'][i])
        cmb_spec['ut'].append(obs_spec['ut'][i])
        cmb_spec['object'].append(obs_spec['object'][i])
        cmb_spec['experiment'].append(obs_spec['experiment'][i])
        cmb_spec['scan'].append(obs_spec['scan'][i])
        cmb_spec['scan_name'].append(obs_spec['scan_name'][i])

        # Is it correct to multiply together navg and num_to_avg?
        cmb_spec['navg'].append(obs_spec['navg'][i] * num_to_avg)

        cmb_spec['spec_len'].append(obs_spec['spec_len'][i])
        cmb_spec['spec_data_type'].append(obs_spec['spec_data_type'][i])

        cmb_spec['crval_freq'].append(obs_spec['crval_freq'][i])
        cmb_spec['crpix_freq'].append(obs_spec['crpix_freq'][i])
        cmb_spec['cdelt_freq'].append(obs_spec['cdelt_freq'][i])
        
        cmb_spec['src_id'].append(obs_spec['src_id'][i])
        cmb_spec['src_ra'].append(obs_spec['src_ra'][i])
        cmb_spec['src_dec'].append(obs_spec['src_dec'][i])
        cmb_spec['src_ra_deg'].append(obs_spec['src_ra_deg'][i])
        cmb_spec['src_dec_deg'].append(obs_spec['src_dec_deg'][i])
        
        cmb_spec['samp_len'].append(obs_spec['samp_len'][i])
        cmb_spec['samp_rate'].append(obs_spec['samp_rate'][i])
        
        # Sum the observation time duration
        cmb_spec['obstime'].append(np.sum(obs_spec['obstime'][i:i+num_to_avg]))
        
        # Add test that i+num_to_avg < os_len

        # Compute mean az and el
        cmb_spec['az'].append(np.mean(obs_spec['az'][i:i+num_to_avg]))
        cmb_spec['el'].append(np.mean(obs_spec['el'][i:i+num_to_avg]))
        
        # mean tsys
        cmb_spec['tsys'].append(np.mean(obs_spec['tsys'][i:i+num_to_avg]))

        # Average together the raw spectra
        cmb_spec['spec'].append(np.mean(obs_spec['spec'][i:i+num_to_avg], axis=0))

        k = k + 1

    num_avg_spec = k

    return num_avg_spec

def sdf_getobs_spec (spec_record, meta_info):
    """
    Populate observation specific meta-data and spectrum for input record.
    The expected record is a GPUSpec spectrum object.
    """
    global obs_spec

    # start with UT date/time as date-obs in isoformat
    lut = spec_record.start_ut()

    obs_spec['spec_idx'].append(0)
    # obs_spec['vdef'].append('    RADI-LSR')
    obs_spec['vdef'].append('RADI-LSR')

    obs_spec['datetime'].append(lut)
    obs_spec['date-obs'].append(lut.isoformat())
    obs_spec['ut'].append(sexig2decim (lut.time()))
    
    obs_spec['object'].append(spec_record.source_name())
    obs_spec['obstime'].append(spec_record.obstime())
    obs_spec['experiment'].append(spec_record.experiment_name())
    obs_spec['scan_name'].append(spec_record.scan_name())
    obs_spec['scan'].append(spec_record.scan_number())
    obs_spec['navg'].append(spec_record.n_averages())
    obs_spec['spec_len'].append(spec_record.spectrum_length())
    obs_spec['spec_data_type'].append(spec_record.spectrum_data_type_size())
    
    obs_spec['spec'].append(spec_record.spectrum())

    obs_spec['samp_len'].append(spec_record.sample_length())
    obs_spec['samp_rate'].append(spec_record.sample_rate())

    # Compute Tsys for this spectrum based on the noise data
    #  as tsys = tnoise * p0/(p1-p0), p0=diode off, p1=diode on
    # TEMPORARY arbitrary assignment of value for tnoise
    tnoise = 100.0
    d = find_index (obs_nois['datetime'], lut, rtype='nearest')
    # print ('SpecTime: {}, NoiseTime: {}, d: {}'.
    #        format(obs_spec['date-obs'][-1],
    #               obs_nois['date-obs'][d],
    #               d))
    tsys = tnoise * obs_nois['mean_power_off'][d] /  \
        (obs_nois['mean_power_on'][d] - obs_nois['mean_power_off'][d])
    obs_spec['tsys'].append(tsys)

    if (meta_info != None):
        a = meta_info.antenna_pos_at_time(lut)
        if (a['measurement'] == None):
            obs_spec['az'].append(-1.0)
            obs_spec['el'].append(-1.0)
        else:
            obs_spec['az'].append(a['fields']['az'])
            obs_spec['el'].append(a['fields']['el'])

        b = meta_info.frequency_map_at_time(lut)
        if (b['measurement'] == None):
            obs_spec['crval_freq'].append(1.0)
            obs_spec['crpix_freq'].append(1.0)
            obs_spec['cdelt_freq'].append(1.0)
        else:
            obs_spec['crval_freq'].append(b['fields']['reference_bin_center_sky_frequency_MHz'] *
                                          1000000.0)
            obs_spec['crpix_freq'].append(b['fields']['reference_bin_index'])
            obs_spec['cdelt_freq'].append(b['fields']['frequency_delta_MHz']
                                          * 1000000.0 / b['fields']['bin_delta'])

        c = meta_info.source_at_time(lut)
        if (c['measurement'] == None):
            obs_spec['src_id'].append('SourceID')
            obs_spec['src_ra'].append('000000.00')
            obs_spec['src_dec'].append('+000000.0')
            obs_spec['src_ra_deg'].append(0.0)
            obs_spec['src_dec_deg'].append(0.0)
        else:
            obs_spec['src_id'].append(c['fields']['source'])
            obs_spec['src_ra'].append(c['fields']['ra'])
            obs_spec['src_dec'].append(c['fields']['dec'])
            rd = (float(c['fields']['ra'][0:2]) + 
                  (float(c['fields']['ra'][2:4]) + 
                   float(c['fields']['ra'][4:])/60.0) / 60.0) * 15.0
            obs_spec['src_ra_deg'].append(rd)
            dd = (float(c['fields']['dec'][1:3]) + 
                  (float(c['fields']['dec'][3:5]) + 
                   float(c['fields']['dec'][5:])/60.0) / 60.0)
            if (c['fields']['dec'][0] == '-'):
                dd = -1.0 * dd
            obs_spec['src_dec_deg'].append(dd)

    else:
        obs_spec['az'].append(-1.0)
        obs_spec['el'].append(-1.0)

        obs_spec['crval_freq'].append(1.0)
        obs_spec['crpix_freq'].append(1.0)
        obs_spec['cdelt_freq'].append(1.0)

        obs_spec['src_id'].append('SourceID')
        obs_spec['src_ra'].append('000000.00')
        obs_spec['src_dec'].append('+000000.0')
        obs_spec['src_ra_deg'].append(0.0)
        obs_spec['src_dec_deg'].append(0.0)

    #print ('{} {}'.format(obs_spec['scan_name'], obs_spec['scan']))
    #print ('{} {}'.format(obs_spec['date-obs'], obs_spec['ut']))

    return

def sdf_getobs_nois (nois_record, meta_info):
    """
    Populate observation specific meta-data and noise data for input record.
    The expected record is a GPUNoise object.
    """
    global obs_nois

    # start with UT date/time as date-obs in isoformat
    lut = nois_record.start_ut()
    obs_nois['datetime'].append(lut)
    obs_nois['date-obs'].append(lut.isoformat())
    obs_nois['ut'].append(sexig2decim (lut.time()))
    
    obs_nois['object'].append(nois_record.source_name())
    obs_nois['obstime'].append(nois_record.obstime())
    obs_nois['experiment'].append(nois_record.experiment_name())
    obs_nois['scan_name'].append(nois_record.scan_name())
    obs_nois['scan'].append(nois_record.scan_number())

    obs_nois['accum_len'].append(nois_record.accumulation_length())
    obs_nois['switch_freq'].append(nois_record.switching_frequency())
    obs_nois['blanking_per'].append(nois_record.blanking_period())

    obs_nois['noise'].append(nois_record.noise())
    obs_nois['mean_power_on'].append(nois_record.mean_power(state='on'))
    obs_nois['mean_power_off'].append(nois_record.mean_power(state='off'))
    
    if (meta_info != None):
        a = meta_info.antenna_pos_at_time(lut)
        obs_nois['az'].append(a['fields']['az'])
        obs_nois['el'].append(a['fields']['el'])
    else:
        obs_nois['az'].append(-1.0)
        obs_nois['el'].append(-1.0)

    #print ('{} {}'.format(obs_nois['date-obs'], obs_nois['ut']))

    return

def sdf_getsite (origin=None, site=None, telescope=None, instrument=None):
    """
    Populate site metadata structure
    site is a triple {lat, lon, alt}
    telescope and instrument are the respective names.
    """
    global site_meta

    # default to Haystack 37-m (for now)
    site_meta = { 'origin': 'Haystack Observatory',
                  'site': {'lat'  : +42.62333333,
                           'lon'  : -71.48833333,
                           'elev' : 131 },
                  'telescope'  : '37-meter',
                  'instrument' : 'GPU spectrometer',
                  'beameff'    : 1.0,
                  'forweff'    : 1.0}

    if (origin != None):
        site_meta['origin'] = origin

    if (site != None):
        site_meta['site'] = site

    if (telescope != None):
        site_meta['telescope'] = telescope

    if (instrument != None):
        site_meta['instrument'] = instrument

    return

def sdf_getwthr (dewpoint=None,    humidity=None, pressure=None,
                 temperature=None, winddir=None,  windspeed=None,
                 tau=None):
    """
    Populate weather metadata structure
    Default values (from SLALIB refraction code):
      tdk = 273.15 Default temperature (K)
      pmb = 1013.25 Default pressure (mBars == hPa)
      rh  = 0.5 Default relative humidity (0.0 - 1.0)
      tlr = 0.0065 Default Tropospheric lapse rate (K/meter)
    """
    global wthr_meta

    # defaults
    wthr_meta = { 'dewpoint'  : 273.15,
                  'humidity'  : 0.5,
                  'pressure'  : 1013.25,
                  'toutside'  : 293.15,
                  'winddir'   : 0.0,
                  'windspeed' : 0.0,
                  'tau-atm'   : 0.0 }

    if (dewpoint != None):
        wthr_meta['dewpoint'] = dewpoint

    if (humidity != None):
        wthr_meta['humidity'] = humidity

    if (pressure != None):
        wthr_meta['pressure'] = pressure

    if (temperature != None):
        wthr_meta['toutside'] = temperature

    if (winddir != None):
        wthr_meta['winddir'] = winddir

    if (windspeed != None):
        wthr_meta['windspeed'] = windspeed

    if (tau != None):
        wthr_meta['tau-atm'] = tau

    return

def sdf_getwcs (maxis=None, maxisN=None, ctypeN=None, crvalN=None,
                crpixN=None, cdeltN=None):
    """
    Populate default WCS column header info
    """
    global wcs_meta

    # defaults
    if (maxis == None):
        wcs_meta['maxis']  = 4
        wcs_meta['maxisN'] = [2,1,1,1]
        wcs_meta['ctypeN'] = ['FREQ', 'RA', 'DEC', 'STOKES']
        wcs_meta['crvalN'] = [1.0]*4
        wcs_meta['crpixN'] = [1.0]*4
        wcs_meta['cdeltN'] = [1.0]*4
    else:
        wcs_meta['maxis']  = maxis
        wcs_meta['maxisN'] = maxisN
        wcs_meta['ctypeN'] = ctypeN
        wcs_meta['crvalN'] = crvalN
        wcs_meta['crpixN'] = crpixN
        wcs_meta['cdeltN'] = cdeltN

    return

def altaz2radec (alt, az, obstime, site, wthr=None):
    """
    From Alt, Az, UT, Location compute
    RA, Dec, galactic l,b and lst and barycentric RV correction
    Accepts either single values, or lists (ie alt = [a1, a2, .., aN]
    and returns corresponding type.
    """

    osi = EarthLocation(lat=site['lat']*u.deg,
                        lon=site['lon']*u.deg,
                        height=site['elev']*u.m)

    oti = Time(obstime, scale='utc', location=osi)

    # lst = oti.sidereal_time('mean').to_string(sep='')
    lst = oti.sidereal_time('mean').value * 3600.0 * u.second

    azel = SkyCoord(alt=alt*u.deg, az=az*u.deg, frame='altaz', obstime=oti,
                    location=osi, pressure=0)

    eqc = azel.transform_to('icrs')
    glc = azel.transform_to('galactic')

    # compute barycentric radial velocity correction
    baryctr_corr = azel.radial_velocity_correction('barycentric')
    #                                           obstime=oti, location=osi)
    
##    # compute the radial component of the LSR velocity along the line
##    # of site to the object ra, dec

##    # start with cartesian form of galactic coords of direction to object
##    cart_dat = glc.data.to_cartesian()
##    cart_unit = cart_dat / cart_dat.norm()

##    # Get solar velocity in cartesian galactocentric coordinates.

##    v_sun = Galactocentric.galcen_v_sun.to_cartesian()

##    # Now project the solar velocity wrt the LSR along the light of sight
##    lsr_corr = v_sun.dot(cart_unit)

    # temporary - the astropy.coordinates for python2 does not include
    # the transformations for quick computation of the projection of the LSR
    # velocity

    # Computing the solar velocity relative to the LSR along the line
    #  of site to the observed object(s).

    # Refs:
    # - Delhaye, J., 1965, Galactic Structure, Stars and Stellar
    #   Systems, Vol. 5, p. 61, Chicago University Press,
    #   (see esp section 2)
    # - Kerr, F., & Lynden-Bell, D. 1986, MNRAS, 221, 1023.
    # - Reid, N., et al. 2009, ApJ, 700, 137-148.
    #   (see esp Table 2 and the Appendix)
    # - Schonrich, R., et al, 2010, MNRAS, 403, 1829.

    # compute unit vector in the direction of the object from galactic coords
    # and dot that with the (U,V,W) components of the solar motion.

    # - the nominal values used are supposed to be from Schonrich et
    #   al (2010), with (U,V,W) = (11.1, 12.24, 7.25) km/s
    # - if we decide to use a different convention, it should be
    #   straightforward to modify
    # B&T - pg14 - solar motion relative to LSR is 
    #  16.5 km/s in dir l=+53deg, b=+25deg
    # This comes from Kerr & Lynden-Bell

    # Kerr, F. & Lynden-Bell, D. 1986, MNRAS, 221, 1023
    # Footnote to section 1.4:
    # *In galactic Cartesian components X=r cosl cosb, etc. 
    #  Xdot = U=10.0,  Ydot = V=15.4, Zdot = W=7.8 km/s
    # (nb - right handed coordinate system, w/ X pointing from Sun to GC.)

    # Delhaye, J., 1965. Galactic Structure, Stars and Stellar
    #  Systems, Vol. 5, p. 61, Chicago University Press,

    # Delhaye, 1965 - peculiar motion given in Pi, Theta, Z, lefthanded
    #   coordinate system. Convert by flipping sign on Pi to get U. V=Theta,
    #   W = Z.

    #  section 2, Solar Motion:
    #  subsec 2.1  wrt circ vel.
    #  weighted mean of measures wrt populations in table 2:
    #    (U,V,W) = (+9, +12, +7) km/s, in right handed form (pg 73)
    #  equals 16.5 km/s in dir l,b = 53, 25deg

    #  subsect 2.2 std sol motion: wrt A-G MS stars, giants and supergiants
    #    (U,V,W) = (+10.4, +14.8, +7.3) km/s, in right handed form (pg 73)
    #  equals 19.5 km/s in dir l,b = 56, 23deg

    #  subsect 2.3: basic sol motion: wrt most freq occuring in local neighborhood
    #    (U,V,W) = (+9, +11, +6) km/s, in right handed form (pg 74)
    #  equals 15.4 km/s in dir l,b = 51, 23deg

    # Dehnen & Binney 1998 -
    #  U,V,W = (10.0, 5.2, 7.2) km/s Right handed, based on Hipparcos


    # "standard values" listed in Reid, et al 2009, table 5 - from ?
    #  pretty close to Kerr & Lynden-Bell, also Delhaye std sol motion
    #  looking at K&L-B, the text is almost identical to the text in K&L-B
    #  But where does F&L-B get it?
    #  U,V,W = (10.3, 15.3, 7.7) km/s Right handed, based on Hipparcos

    # check Mihalas & Routley, when get a copy

    cgl = np.cos(glc.l.rad)
    sgl = np.sin(glc.l.rad)
    cgb = np.cos(glc.b.rad)
    sgb = np.sin(glc.b.rad)

    # -> Kerr & Lynden-Bell, 1986 - possible "Standard Solar Motion"
    # uvw_klb = [10.0, 15.4, 7.8] * u.kilometer / u.second

    # Dehnen & Binney 1998, based on Hipparcos
    # uvw_db98 = [10.0, 5.2, 7.2] * u.kilometer / u.second

    # Schonrich et al, 2010:
    # uvw_sbd10 = [11.1, 12.24, 7.25] * u.kilometer / u.second

    uvw_sun = uvw_klb

    lsr_corr = cgb*cgl*uvw_sun[0] + cgb*sgl*uvw_sun[1] + sgb * uvw_sun[2]

    return eqc, glc, lst, baryctr_corr, lsr_corr

def sexig2decim (sxtim):
    """
    convert datetime time portion in sexigesimal to decimal seconds.
    ie: input sxtim == dattim.time() element
    """
    h = sxtim.hour
    m = sxtim.minute
    s = sxtim.second
    f = sxtim.microsecond
    d = ((h * 60.0) + m) * 60.0 + s + f/1000000.

    return d

#------------------------------------------------------------------------
# FITS file construction functions

def sdf_primary_hdu (object=None, telescope=None, instrument=None):
    """
    Construct SD FITS file primary HDU. Since most stuff will be
    in the binary table HDU, this is pretty generic, with just a few
    added items.
    Additions for SDFITS came from:
      Liszt, H. S. 1995, A FITS Binary Table Convention for Interchange
      of Single Dish Data in Radio Astronomy.

    """
    global site_meta

    # load site meta-data if not yet done
    if (site_meta['origin'] == None):
        sdf_getmeta(telescope=telescope, instrument=instrument)
    else:
        if (telescope != None):
            site_meta['telescope'] = telescope

        if (instrument != None):
            site_meta['instrument'] = instrument


    # prep the primary HDU header
    hdr = fits.Header()
    hdr['ORIGIN'] = site_meta['origin']
    hdr['DATE'] = (strftime("%Y-%m-%dT%H:%M:%S", gmtime()))

    if (object != None):
        hdr['OBJECT'] = object
    else:
        hdr['OBJECT'] = 'OBJECTID'

    hdr['TELESCOP'] = site_meta['telescope']
    hdr['INSTRUME'] = site_meta['instrument']
    hdr['FWVER']    = '{}'.format(__date__)
    
    # How to put in a comment?

    primary_hdu = fits.PrimaryHDU(header=hdr)

    return primary_hdu

def sdf_bintab_hdr (obsrec, extname='MATRIX', obsmode=None, speclen=0):
    """
    setup common binary table header information
    will return dictionary a, and fits header hdr.
    """
    
    # set up null dictionary for local arrays
    a = {}

    # conversion of alt,az, date/time vectors to ra,dec & l,b & lst &
    # barycentric radial vel correction term
    aeq, agal, alst, brvc, lsrvc = altaz2radec (obsrec['el'], obsrec['az'], 
                                                obsrec['date-obs'], 
                                                site_meta['site'])
    a['equinox'] = [2000.0] * 3
    a['ra']      = aeq.ra.deg
    a['dec']     = aeq.dec.deg
    a['glon']    = agal.l.deg
    a['glat']    = agal.b.deg
    a['lst']     = alst
    a['brvc']    = brvc
    a['lsrvc']   = lsrvc
    
    # Compute the offset in Xi, Eta from the first pointing
    #  Need to make sure the SkyCoord frames for all the Ra,Dec points
    #  are the same. This copy removes the obstime vector, which was
    #  causing trouble.
    zrd = SkyCoord (ra=a['ra'][0]*u.deg, dec=a['dec'][0]*u.deg, frame='icrs')
    ord = SkyCoord (ra=a['ra']*u.deg,    dec=a['dec']*u.deg,    frame='icrs')
    dra, ddec = zrd.spherical_offsets_to(ord)
    a['cdelt2'] = dra
    a['cdelt3'] = ddec

    # add extra header keyword to BinTable HDU
    hdr = fits.Header()
    hdr['BZERO']    = 0.0
    hdr['BSCALE']   = 1.0

    # SINGLE DISH is what is called out in SDFITS def'n
    # hdr['EXTNAME']  = 'SINGLE DISH'
    # MATRIX is what is shown in CLASS samples/docs
    hdr['EXTNAME']  = extname

    # hdr['EXTLEVEL'] = 1   # optional, defaults to 1
    hdr['EXTVER']   = 1   # optional, defaults to 1
    hdr['NMATRIX']  = 1   # required, 1 data set per row

    # WCS Virtual column defaults
    # will get overridden by table columns with same ID
    hdr['MAXIS']  = wcs_meta['maxis']
    for i in range(wcs_meta['maxis']):
        j = i + 1
        hdr['MAXIS{}'.format(j)] = wcs_meta['maxisN'][i]
        hdr['CTYPE{}'.format(j)] = wcs_meta['ctypeN'][i]

        if   (wcs_meta['ctypeN'][i] == 'RA'):
            # hdr['CRVAL{}'.format(j)] = a['ra'][0]
            hdr['CRVAL{}'.format(j)] = obsrec['src_ra_deg'][0]
            hdr['CDELT{}'.format(j)] = wcs_meta['cdeltN'][i]
            hdr['CRPIX{}'.format(j)] = wcs_meta['crpixN'][i]
        elif (wcs_meta['ctypeN'][i] == 'DEC'):
            # hdr['CRVAL{}'.format(j)] = a['dec'][0]
            hdr['CRVAL{}'.format(j)] = obsrec['src_dec_deg'][0]
            hdr['CDELT{}'.format(j)] = wcs_meta['cdeltN'][i]
            hdr['CRPIX{}'.format(j)] = wcs_meta['crpixN'][i]
        elif (wcs_meta['ctypeN'][i] == 'FREQ'):
            if (speclen != 0):
                hdr['MAXIS{}'.format(j)] = speclen
            hdr['CRVAL{}'.format(j)] = obsrec['crval_freq'][0]
            hdr['CRPIX{}'.format(j)] = obsrec['crpix_freq'][0]
            hdr['CDELT{}'.format(j)] = obsrec['cdelt_freq'][0]
        else:
            hdr['CRVAL{}'.format(j)] = wcs_meta['crvalN'][i]
            hdr['CDELT{}'.format(j)] = wcs_meta['cdeltN'][i]
            hdr['CRPIX{}'.format(j)] = wcs_meta['crpixN'][i]

    # Site Metadata
    hdr['TELESCOP'] = site_meta['telescope']
    hdr['INSTRUME'] = site_meta['instrument']
    hdr['SITELONG'] = site_meta['site']['lon']
    hdr['SITELAT']  = site_meta['site']['lat']
    hdr['SITEELEV'] = site_meta['site']['elev']

    # freq & velocity default info
    hdr['FOFFSET']  = 0.0  # class hdr
    hdr['RESTFREQ'] = 1.0  # class hdr
    # hdr['VELO-LSR'] = 0.0  # class hdr
    # hdr['VLSR']     = 0.0  # sdfits example hdr
    hdr['VELDEF']   = 'RADI-LSR    '  # class hdr
    hdr['DELTAV']   = 0.0  # class hdr

    hdr['BEAMEFF']  = site_meta['beameff']
    hdr['FORWEFF']  = site_meta['forweff']
    
    # Presume equinox/epoch of coordinates is J2000/2000
    hdr['EQUINOX'] = 2000.0

    # Environmental Metadata
    hdr['DEWPOINT'] = wthr_meta['dewpoint']
    hdr['HUMIDITY'] = wthr_meta['humidity']
    hdr['PRESSURE'] = wthr_meta['pressure']
    hdr['TAU_ATM']  = wthr_meta['tau-atm']
    hdr['TOUTSIDE'] = wthr_meta['toutside']
    hdr['WINDDIRE'] = wthr_meta['winddir']
    hdr['WINDSPEE'] = wthr_meta['windspeed']

    if ( obsmode != 'None'):
        # should limit options to {LINE,CONT,PULS} x 
        #                         {PSSW,FQSW,BMSW,PLSW,LDSW,TLPW}
        hdr['OBSMODE'] = obsmode


    return a, hdr

def sdf_spectable_hdu(obsmode=None, max1=0):
    """
    Construct a FITS binary table HDU for spectrum data in single dish
    (SDFITS) radio data format.

    Define Table Columns - set up data arrays, then define column
    specs then create ensemble of columns, and finally make a Binary
    Table HDU from the defined col set
    """

    # default spectrum length
    # Currently assumes that all spectra will be the same length
    #  and so uses the length of the first one to set the size
    if (max1 == 0):
        # dsize = '{}E'.format(wcs_meta['maxisN'][0])
        dsizeval = int(obs_spec['spec_len'][0])
        dsize = '{}E'.format(dsizeval)
    else:
        dsize = '{}E'.format(max1)

    # set up null dictionary for columns
    c = {}

    # set up null dictionary for local arrays
    a = {}

    # a, hdr = sdf_bintab_hdr (obs_spec, extname='MATRIX', obsmode=obsmode)
    a, hdr = sdf_bintab_hdr (obs_spec, extname='SINGLE DISH', obsmode=obsmode,
                             speclen=dsizeval)
    
    #c['scan']     = fits.Column(name='SCAN',     format='256A',
    #                            array=obs_spec['scan'])
    
    c['scan']     = fits.Column(name='SCAN',     format='1J',
                                array=obs_spec['scan'])

    # spectrum number w/in scan - running integer starting w/ 1

    # polarization information

    c['object']   = fits.Column(name='OBJECT',   format='12A', 
                                array=obs_spec['object'])

    # Check for Freq columns to pass into WCS cols in the bintable
    # CRVAL, CRPIX, CDELT (check for CD11?)

    # Check for RA, Dec columns to pass into CRVALs in table
    # ra,dec are the source catalogue ra and dec
    for i in range(wcs_meta['maxis']):
        j = i + 1
        if   (wcs_meta['ctypeN'][i] == 'RA'):
            c['src_rad']   = fits.Column(name='CRVAL{}'.format(j),
                                         format='1E', unit='DEGREES',
                                         array=obs_spec['src_ra_deg'])
            

        elif (wcs_meta['ctypeN'][i] == 'DEC'):
            c['src_decd']  = fits.Column(name='CRVAL{}'.format(j),   
                                         format='1E', unit='DEGREES',
                                         array=obs_spec['src_dec_deg'])

        elif (wcs_meta['ctypeN'][i] == 'FREQ'):
            c['freq_crval']   = fits.Column(name='CRVAL{}'.format(j),
                                            format='1E', unit='HZ',
                                            array=obs_spec['crval_freq'])
            c['freq_crpix']   = fits.Column(name='CRPIX{}'.format(j),
                                            format='1E', unit='PIXEL',
                                            array=obs_spec['crpix_freq'])
            c['freq_cdelt']   = fits.Column(name='CDELT{}'.format(j),
                                            format='1E', unit='HZ',
                                            array=obs_spec['cdelt_freq'])

    # Encoder based RA, DEC
    c['enc_ra']   = fits.Column(name='ENCRA',
                                format='1E', unit='DEGREES',
                                array=a['ra'])

    c['enc_decd']   = fits.Column(name='ENCDEC',
                                  format='1E', unit='DEGREES',
                                  array=a['dec'])

    # Source catalogue ID, RA and Dec in string sexigesimal form
    c['src_id']   = fits.Column(name='SRCID',   format='12A', 
                                array=obs_spec['src_id'])

    c['src_ra']   = fits.Column(name='SRCRA',   format='9A', 
                                array=obs_spec['src_ra'])

    c['src_dec']  = fits.Column(name='SRCDEC',   format='9A', 
                                array=obs_spec['src_dec'])

    # Spectrum running index in the FITS file
    c['spec_idx'] = fits.Column(name='SUBSCAN',  format='1J', 
                                array=obs_spec['spec_idx'])

    # compute this from the noise power
    c['tsys']       = fits.Column(name='TSYS',     format='1E', unit='K',
                                  array=obs_spec['tsys'])

    # a['imagfreq'] = ?
    c['imagfreq']   = fits.Column(name='IMAGFREQ', format='1E', unit='HZ')
    #                              array=a['restfreq'])

    # a['tau-atm'] = ?
    c['tau-atm']    = fits.Column(name='TAU_ATM', format='1E')
    #                              array=a['tau-atm'])

    # a['mh2o'] = ?
    c['mh2o']       = fits.Column(name='MH2O', format='1E')
    #                              array=a['mh2o'])

    # a['pressure'] = ?
    c['pressure']   = fits.Column(name='PRESSURE', format='1E', unit='hPa')
    #                              array=a['pressure'])

    # a['tchop'] = ?
    c['tchop']      = fits.Column(name='TCHOP',    format='1E', unit='K')
    #                              array=a['tchop'])

    # Az,El from the metadata
    c['el']        = fits.Column(name='ELEVATIO', format='1E', unit='DEGREES',
                                 array=obs_spec['el'])
    c['az']        = fits.Column(name='AZIMUTH',  format='1E', unit='DEGREES',
                                 array=obs_spec['az'])

    # Galactic longitude and latitude computed from az,el,telescope site,
    # ut. Added for debuging.
    # c['glon']      = fits.Column(name='GLON', format='1E', unit='DEGREES',
    #                              array=a['glon'])

    # c['glat']      = fits.Column(name='GLAT',  format='1E', unit='DEGREES',
    #                              array=a['glat'])

    c['date-obs']  = fits.Column(name='DATE-OBS', format='26A', 
                                 array=obs_spec['date-obs'])
    
    c['ut']        = fits.Column(name='UT',       format='1D', 
                                 array=obs_spec['ut'])
    # a['lst'] = ?
    c['lst']       = fits.Column(name='LST',      format='1D', 
                                 array=a['lst'])

    c['obstime']   = fits.Column(name='OBSTIME', format='1E', unit='SECONDS',
                                 array=obs_spec['obstime'])


    c['brvc']      = fits.Column(name='BARYCORR', format='1E', unit='M/S',
                                 array=a['brvc'].to(u.m/u.s) )
    
    c['lsrvc']     = fits.Column(name='VLSRCORR', format='1E', unit='M/S',
                                 array=a['lsrvc'].to(u.m/u.s) )
    
    # c['veld']     = fits.Column(name='VELDEF', format='12A',
    #                             array = (obs_spec['vdef']))
    #                            array=np.array(obs_spec['vdef'],
    #                                           dtype=np.unicode_))
    # print ('CVDEF {}'.format(c['veld']))

    c['spec']     = fits.Column(name='SPECTRUM',  format=dsize, unit='POWER',
                                 array=obs_spec['spec'])


    # temporary
    #c['samp_len'] = fits.Column(name='SAMPLEN', format='1E', unit='Number',
    #                             array=obs_spec['samp_len'])
    #c['samp_rate']= fits.Column(name='SAMPRATE', format='1E', unit='HZ',
    #                             array=obs_spec['samp_rate'])

    cols = fits.ColDefs([c[i] for i in sorted(c.keys())])
    # cols.info()
    hdu  = fits.BinTableHDU.from_columns(cols, header=hdr)
    
    # hdu.data['VELDEF'][0] = b'RADI-LST    T'
    # print ('veldef: {}'.format(hdu.data['VELDEF']))

    print ('{}'.format(hdu.columns))

    return hdu

def sdf_noistable_hdu(obsmode=None, max1=0):
    """
    Construct a FITS binary table HDU for noise data in single dish
    (SDFITS) radio data format.

    Define Table Columns - set up data arrays, then define column
    specs then create ensemble of columns, and finally make a Binary
    Table HDU from the defined col set
    """

    # set up null dictionary for columns
    c = {}

    # set up null dictionary for local arrays
    a = {}

    a, hdr = sdf_bintab_hdr (obs_nois, extname='NOISE', obsmode=obsmode)
    
    c['scan']     = fits.Column(name='SCAN',     format='256A',
                                array=obs_nois['scan'])

    c['object']   = fits.Column(name='OBJECT',   format='12A', 
                                array=obs_nois['object'])

    # Check for RA, Dec columns to pass into CRVALs in table
    for i in range(wcs_meta['maxis']):
        j = i + 1
        if   (wcs_meta['ctypeN'][i] == 'RA'):
            c['ra']   = fits.Column(name='CRVAL{}'.format(j),
                                         format='1E', unit='DEGREES',
                                         array=a['ra'])

        elif (wcs_meta['ctypeN'][i] == 'DEC'):
            c['dec']   = fits.Column(name='CRVAL{}'.format(j),
                                         format='1E', unit='DEGREES',
                                         array=a['dec'])

    # a['tsys'] = ?
    c['tsys']       = fits.Column(name='TSYS',     format='1E', unit='K')
    #                              array=a['tsys'])

    # a['imagfreq'] = ?
    c['imagfreq']   = fits.Column(name='IMAGFREQ', format='1E', unit='HZ')
    #                              array=a['restfreq'])

    # a['tau-atm'] = ?
    c['tau-atm']    = fits.Column(name='TAU_ATM', format='1E')
    #                              array=a['tau-atm'])

    # a['mh2o'] = ?
    c['mh2o']       = fits.Column(name='MH2O', format='1E')
    #                              array=a['mh2o'])

    # a['pressure'] = ?
    c['pressure']   = fits.Column(name='PRESSURE', format='1E', unit='hPa')
    #                              array=a['pressure'])

    # a['tchop'] = ?
    c['tchop']      = fits.Column(name='TCHOP',    format='1E', unit='K')
    #                              array=a['tchop'])

    c['el']        = fits.Column(name='ELEVATIO', format='1E', unit='DEGREES',
                                 array=obs_nois['el'])
    c['az']        = fits.Column(name='AZIMUTH',  format='1E', unit='DEGREES',
                                 array=obs_nois['az'])

    c['date-obs']  = fits.Column(name='DATE-OBS', format='26A', 
                                 array=obs_nois['date-obs'])
    
    c['ut']        = fits.Column(name='UT',       format='1D', 
                                 array=obs_nois['ut'])
    # a['lst'] = ?
    c['lst']       = fits.Column(name='LST',      format='1D', 
                                 array=a['lst'])

    c['obstime']   = fits.Column(name='OBSTIME', format='1E', unit='SECONDS',
                                 array=obs_nois['obstime'])


    # TBD construct noise columns based on class defs from hose
    
    # Currently assumes that all spectra will be the same length
    #  and so uses the length of the first one to set the size
#    if (max1 == 0):
#        # dsize = '{}E'.format(wcs_meta['maxisN'][0])
#        dsize = '{}E'.format(int(obs_nois['spec_len'][0]))
#    else:
#        dsize = '{}E'.format(max1)
#
#    c['spec']     = fits.Column(name='SPECTRUM',  format=dsize, unit='POWER',
#                                 array=obs_spec['spec'])


    cols = fits.ColDefs([c[i] for i in sorted(c.keys())])
    hdu  = fits.BinTableHDU.from_columns(cols, header=hdr)

    print ('{}'.format(hdu.columns))

    return hdu

def sdf_mkfits (ofile=None):
    """
    Construct full fits file
    """

    sdf_getsite()
    sdf_getwthr()
    sdf_getwcs(maxis=4, maxisN=[2,1,1,1],
               ctypeN=['FREQ', 'RA', 'DEC', 'STOKES'], 
               crvalN=[1]*4, crpixN=[1]*4, cdeltN=[1]*4)
    
    # Loading the obs_spec and obs_nois dictionaries is done outside
    #  this.
    # sdf_getobs_spec()

    phdu = sdf_primary_hdu (telescope='Westford')
    shdu = sdf_spectable_hdu (obsmode='LINEPSSW')
    
    # include primary and table HDUs into one
    hdu1 = fits.HDUList([phdu, shdu])

    # hdu1[1].data['VELDEF'][0] = str('    RADI-LST').encode('ascii')
    # print ('veldef: {}'.format(hdu1[1].data['VELDEF']))
    
    # Write out FITS table file
    if (ofile != None):
        hdu1.writeto (ofile)
        hdu1.close()
        
    return

#------------------------------------------------------------------------
# Upper level driver routines - handle directory listing/searching etc.
def loop_over_dirs (inputs, num_to_avg=1):
    """
    Overall driver to load in spectra and noise data in all 
    directories in the list.
    [NOT YET IMPLEMENTED OPTION:
      maxperfits == max number of spectra per fits file. If < 0, do all.
    ]
    """

    global obs_spec
    global cmb_spec

    # Expect argument to be directory with scans or scan directories
    # argone = sys.argv[1]
    argone = inputs
    print ('{}'.format(argone))

    # within each scan directory, construct lists of spec, noise and
    # metadata files
    d, fs, fn, fm, ff = r.construct_lists (argone)

    for n in range(len(d)):
        numnois = load_noise   (n, d[n], fn[n], fm[n], ff[n])
        numspec = load_spectra (n, d[n], fs[n], fm[n], ff[n])
        if ((numspec > 0) or (numnois > 0)):
            # handle the case of ., or ./
            if ( (d[n] == '.') or (d[n] == './') or (d[n] == '../')):
                froot = (os.path.basename(os.path.abspath(d[n])))
            else:
                # sel-181216 - possible change to next line - not yet tried
                # froot = (os.path.basename(os.path.abspath(d[n])))
                froot = os.path.basename(d[n])

            ofile = '{}/{}.fits'.format(d[n],froot)

            # insert raw spectral record simple combination here
            if (num_to_avg > 1):
                simple_combine_spec (num_to_avg)
                for j in cmb_spec:
                    obs_spec[j] = cmb_spec[j]
                print (obs_spec['spec_idx'])

            sdf_mkfits(ofile=ofile)
        
    # print ('{}'.format(obs_spec['ut']))
    
    return

def load_spectra(idnum, d, fs, fm, ff):
    """
    Overall driver to load in spectra in nth directory in the list
    idnum == n'th directory - currently not used
    d == dir path
    fs == list of spec files
    fm == list of meta files
    ff == list of fits files
    [NOT YET IMPLEMENTED OPTION:
      maxper == max number of spectra to insert in a fits file. If < 0, do all.
    ]
    """
    global obs_spec
    
    anyfits = len(ff)
        
    print ('Start {}'.format(dt.datetime.now().ctime()))
    print ('Dir: {}'.format(d))
    print ('  Spec files: {}'.format(len(fs)))
    print ('  Metadata file(s): {} {}'.format(len(fm), fm))
    print ('  FITS files: {} {}'.format(anyfits, ff))
    if (anyfits > 0):
        print ('FOUND FITS FILES - SKIPPING THIS DIR')
        return 0

    # loop and load metadata files.  I'm assuming that normally there
    # is only one per dierctory, but just in case have the loop
    # option.
    if (len(fm) <= 0):
        print ('No metadata file in this directory')
        md = None
    else:
        for ifm in fm:
            md = r.GPUMeta(ifm)
            v1 = md.antenna_pos()
            print ('  META - antpos - {}'.format(v1[0]))


    # loop and load spectrum files
    ct = 0
    for ifs in fs:

        if (ct  == 0):
            sp = r.GPUSpec(ifs, echo=True)
        else:
            sp = r.GPUSpec(ifs)

        lut = sp.start_ut()
        # print ('{} {}'.format(lut, lut.isoformat()))
        sdf_getobs_spec (sp, md)
        
        if (ct %100 == 0):
            ut, ob, ex, sc, so = sp.fits_hdr()
            print ('  M+S - {} {} {} {}'.\
                   format(ct, ut,
                          md.antenna_pos_at_time(ut)['fields']['az'],
                          md.antenna_pos_at_time(ut)['fields']['el']))
        ct += 1

    # ensure that each array in obs_spec is in increasing time sort order
    # set up separate list of datetime as the sort index
    #  zip together all the other obs_spec lists after the sort index
    # sort and then copy back into obs_spec.

    obs_spec = sort_dict_of_lists (obs_spec, 'datetime')

    # Now, put monotonic index into spec_idx in the sorted obs_spec
    # This should also be the order that the spectra wind up in the FITS file
    
    for sct in range(len(obs_spec['spec_idx'])):
        obs_spec['spec_idx'][sct] = sct + 1

    print ('End {}'.format(dt.datetime.now().ctime()))
    print ('')
        
    return ct

def load_noise(idnum, d, fn, fm, ff):
    """
    Overall driver to load in noise files in nth directory in the list
    idnum == n'th directory - currently not used
    d == dir path
    fn == list of noise files
    fm == list of meta files
    ff == list of fits files
    """
    global obs_nois
    
    anyfits = len(ff)
        
    print ('Start {}'.format(dt.datetime.now().ctime()))
    print ('Dir: {}'.format(d))
    print ('  Noise files: {}'.format(len(fn)))
    print ('  Metadata file(s): {} {}'.format(len(fm), fm))
    print ('  FITS files: {} {}'.format(anyfits, ff))
    if (anyfits > 0):
        print ('FOUND FITS FILES - SKIPPING THIS DIR')
        return 0

    # loop and load metadata files.  I'm assuming that normally there
    # is only one per dierctory, but just in case have the loop
    # option.
    if (len(fm) <= 0):
        print ('No metadata file in this directory')
        md = None
    else:
        for ifm in fm:
            md = r.GPUMeta(ifm)
            v1 = md.antenna_pos()
            print ('  META - antpos - {}'.format(v1[0]))


    # loop and load noise files
    ct = 0
    for ifn in fn:
        
        if (ct == 0):
            npw = r.GPUNoise(ifn, echo=True)
        else:
            npw = r.GPUNoise(ifn)

        lut = npw.start_ut()
        # print ('{} {}'.format(lut, lut.isoformat()))
        sdf_getobs_nois (npw, md)
        
        if (ct %100 == 0):
            ut, ob, ex, sc, so = npw.fits_hdr()
            print ('  M+S - {} {} {} {}'.\
                   format(ct, ut,
                          md.antenna_pos_at_time(ut)['fields']['az'],
                          md.antenna_pos_at_time(ut)['fields']['el']))
        ct += 1
        
    # ensure that each array in obs_spec is in increasing time sort order
    # set up separate list of datetime as the sort index
    #  zip together all the other obs_spec lists after the sort index
    # sort and then copy back into obs_spec.

    obs_nois = sort_dict_of_lists (obs_nois, 'datetime')
    
    print ('End {}'.format(dt.datetime.now().ctime()))
    print ('')
        
    return ct

#------------------------------------------------------------------------
# Execute as script

if __name__ == '__main__':
    import sys

    # Pull in the command line
    # expect argv[0] == script, [1] == output file name
    argv = sys.argv
    argc = len(argv)

    if (argc < 2):
        print ('{}'.format(__usage__))
    else:
        if (argc == 3):
            a = loop_over_dirs(argv[1], num_to_avg=int(argv[2]))
        else:
            a = loop_over_dirs(argv[1])

